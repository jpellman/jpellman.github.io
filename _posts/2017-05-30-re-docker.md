---
layout: post
title:  "Re: Singularity"
date:   2017-05-30 20:10:00
permalink: /first-post.html
---

http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0177459

The article doesn't really discuss how Singularity would encode state.  This is also necessary when discussing reproducibility.  Configuration management should also be added in.  This would document the state a server was in prior to a workflow being run and then future servers could converge upon that state prior to re-running the workflow.  To an extent this is accomplished with the docker2singularity tool, but this is inelegant and not as full featured as CFEngine/Puppet/Chef/Saltstack.

Another feature of using config management would be the ability for future experimenters to manipulate environments via the infrastructure as code paradigm.  I.e., if someone wanted to re-run a workflow with a new or older version of BLAS, they could edit a state file of some kind and then deploy a new container with the newer BLAS to see if they achieved the same result.

We don't want pets, we want cattle for Big Science.

Config management also addresses some of the concerns raised by titus [here](http://ivory.idyll.org/blog/2017-pof-software-archivability.html).  Namely, if we aim for convergence rather than absolute reproduciblity our workflows will probably be more robust as technology evolves.  Also, IaaS (as mentioned earlier) would allow much easier remixing.

To what extent can the features introduced by Singularity be folded back into currently existent container platforms and, conversely, to what extent can Singularity benefit from what the open source community has created?  The article makes a very strong point against Docker due to the privilege escalation exploit (although technically this was fixed as of Docker 1.10) and perhaps, more poignantly the need for containers to run without a daemon on HPC architectures, but what about LXC, LXD or Open VZ?  For this, I turned to the website and found the following:

http://singularity.lbl.gov/faq#how-does-singularity-relatediffer-from-other-container-systems-like-openvz-lxclxd-etc

It feels like other container systems could benefit greatly from some of Singularity's optimizations and conversely, Singularity could benefit from being affiliated with a more mainstream containerization platform (with more developers and equally importantly, more support from third-parties such as IBM, Google, Canonical, and Virtuozzo).

I'm also not sure if I understand the necessity of preventing root access within a container.

Furthermore, I'm very wary of any projects out there with a bus factor of 2 or less, and it seems like Singularity is mostly driven by Greg Kurtzer.  If he were to randomly get a heart attack, the project would wither, quickly fade into an unmaintained state, and potentially break with newer Linux distros.  This would leave a large number of workflows unrunnable and thus unreproducible.  

My point here is that, if we truly care about reproduciblity, we can't shirk mainstream platforms.

Also, if we are to take the containerization metaphor to its logical conclusion, it stands to reason that varied and fragmented standards are ultimately antithetical to the spirit of containerization.  As pointed out in a well-done video by Wendover Productions, the success of real world shipping containers and the revolution they created in global trade was due in large part to the fact that multiple countries accepted a universal standard that made international exchanges truly seamless.

https://www.youtube.com/watch?v=F-ZskaqBshs

Another point: If the HPC community rejects mainstream standards and invents their own idiosyncratic (but better for their specific purpose in some ways), they're creating an unnecessary barrier to translating scientific workflows from basic research labs to mainstream commercial services.
