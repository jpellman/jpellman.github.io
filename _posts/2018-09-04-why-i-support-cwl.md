---
layout: post
title: "Why I Support the Common Workflow Language"
date:   2018-09-04 21:26:54
comments: true
permalink: /cwl-support.html
---

I've been wanting to write a post about [Common Workflow Language](https://www.commonwl.org/) (CWL) for a while now and, realizing that if I don't do so now I likely never will, have decided to embark upon an attempt at articulating my thoughts about why I support this project.  For those who are unfamiliar with CWL, it is essentially a simple YAML-based syntax for expressing input-output relations between programs in a workflow.  These relations / workflows can be expressed in what is called a [directed acyclic graph](https://en.wikipedia.org/wiki/Directed_acyclic_graph) or a graph in which no node is visited more than once and no loops exist.  I've been following it sporadically since I stopped working in science since it duplicates a lot of the functionality of other flow-based tools used by scientists such as [Nipype](https://nipype.readthedocs.io/en/latest/) or [Galaxy](https://usegalaxy.org/), but in a platform and field agnostic way.

This agnosticism means that scientists and data engineers using CWL can switch between different job schedulers with different ways of determining when a machine has enough resources to optimally execute a specific step within the workflow.  Essentially, programs wrapped in CWL can be thought of like a CPU instruction set and a job scheduler that knows how to interpret CWL can be thought of like a hardware backend that knows certain tricks to make those CWL-wrapped commands execute more quickly.  If a scientist or engineer is using one backend, but then discovers that another backend uses slightly more clever algorithms that result in 15% more performance, the portability of CWL allows one to jump from one implementation to another with ease.

CWL also enforces good practices in scientific computing, by [emphasizing interfaces over implementations](https://joshldavis.com/2013/07/01/program-to-an-interface-fool/).  When you wrap a command line tool in CWL, you not only have something practical that allows you to construct a workflow in [Rabix](http://rabix.io/) or [Cromwell](https://cromwell.readthedocs.io/en/stable/LanguageSupport/), you also have a specification of what inputs and outputs a typical scientist in your field would want to have for a particular step in an analysis.  If you have such an specification and you find that current tools in your field are inadequate for some reason (speed, method has inadequate precision, bugs), you can create another tool with the same name that takes in the same inputs and outputs but uses totally different logic under the hood.  In this way, a tool that would benefit from GPU computing can be converted without breaking a previously defined workflow or a tool that was originally limited by CPU can be rewritten to leverage FPGAs or ASICs for great performance gains.

This emphasis on interfaces could also enforce a healthy separation between scientists and the software engineers that develop scientific software.  It's fairly well-established that while many scientists are experienced in their respective fields, not very many are necessarily good at both writing software and keeping up with domain knowledge.  In fact, most scientists don't see the value in formal instruction in software development and consequently produce less than ideal code, a fact that is bemoaned by [a Nature editorial](https://www.nature.com/news/2010/101013/full/467775a.html).  Focusing on defining an interface for a black-box function is something that would not require scientists to stray too far from their realms of expertise, while also allowing an individual who was specialized in software engineering to understand their needs.  In other words, a CWL tool could serve as a common ground where domain specialists from scientific fields and research software engineering could meet in the middle.  Scientists wouldn't need to write shoddy code but would still be able to steer development for their tools.

Lastly, I like CWL because it enforces the use of the Unix shell.  While many other languages (i.e., Python and Perl) have been used as glue languages before, I think that the shell is superior for orchestrating complex pipelines because it doesn't lock you into a particular language ecosystem.  Nipype, for instance, assumes that you will use Python and is heavily biased towards wrapping Python functions directly into a workflow, which would produces lock-in to the Python ecosystem.  If Julia or another language were to produce functionality that was superior to the scientific Python ecosystem, a workflow tool that was heavily biased towards Python would make adoption of Julia functionality more difficult.  Bash is a more level playing field, since bash is only meant to serve as an intermediary to the underlying operating system rather than a super robust language to be used for high performance computing.  I think that it would be better for Python functions to expose themselves via bash using argparse.
